{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "braBzmRpMe7_"
   },
   "source": [
    "# Upside images detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose PyTorch to train my model. The reason I choose PyTorch as in PyTorch things are way more imperative and dynamic: you can define, change and execute nodes as you go, no special session interfaces or placeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IWw-NZf5WfF"
   },
   "source": [
    "**Upside down detector**: Train a model to detect if images are upside down\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0c3cxXKn6JB",
    "outputId": "8ad91982-0906-4787-a405-fdcf282c8b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "drH0gsu8mhtP"
   },
   "outputs": [],
   "source": [
    "# Import Module\n",
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.models import densenet161\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LJAFDfnLnSCW"
   },
   "outputs": [],
   "source": [
    "epoches = 5\n",
    "val_size = 4000\n",
    "valid_loss_min = np.Inf\n",
    "path = '/content/drive/My Drive/AI_Project/Fatima Fellowship/data/'\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "epoch = 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trans = tt.Compose(\n",
    "    [\n",
    "     tt.Resize(224),\n",
    "     tt.ToTensor(),\n",
    "\n",
    "    ]\n",
    ")\n",
    "dataset = ImageFolder(root = path, transform=trans)\n",
    "\n",
    "train_size = len(dataset) - val_size\n",
    "train_set, test_set = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader (train_set, batch_size= batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader (test_set, batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-P_GGrMogP1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3o8tHXlwogT-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaYSrHaSogXp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsQN32RPogaf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Na4ZNRf2ogdJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Upside down image detection using PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
